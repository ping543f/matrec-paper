{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "d7cb94d6c01e6a3d33740a84571d93aa6b2e18b83485f7657d73a09173d8cc2c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "source": [
    "import pymysql\r\n",
    "import pymysql.cursors\r\n",
    "import re\r\n",
    "import datetime\r\n",
    "\r\n",
    "\r\n",
    "ts = datetime.datetime.now().strftime(\"%a%d%b%Y-%I-%M-%S%p\")\r\n",
    "print (\"Current TimeStamp: \",ts)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current TimeStamp:  Wed23Jun2021-04-50-18AM\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "source": [
    "db = pymysql.connect(host='localhost',user='root',password='',database='material-db',cursorclass=pymysql.cursors.DictCursor)\r\n",
    "cur = db.cursor()\r\n",
    "\r\n",
    "cur.execute(\"Select id,papername,doi,clnsent,token,label from datatable\")\r\n",
    "result_list = cur.fetchall()\r\n",
    "\r\n",
    "print(type(result_list))\r\n",
    "print(len(result_list))\r\n",
    "\r\n",
    "\r\n",
    "# db.commit()\r\n",
    "# db.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'list'>\n",
      "42228\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "source": [
    "def clean_text(text):\r\n",
    "    text = re.sub(r\"(^[\\s])\",\"\",text) #removing starting space of any sentence   (^[\\d])\r\n",
    "    text = re.sub(r\"(Ϫ)\",\"-\",text) # replacing this character Ϫ with -\r\n",
    "    text = re.sub(r\"(^[0-9]+)\",\"\",text) #removing starting number of any sentence   (^[\\d])\r\n",
    "    text = re.sub(r\"(\\\\.)\",\".\",text) # replacing \\. with .\r\n",
    "    text = re.sub(r\"(-)\",\" \",text) # replacing - with <space>\r\n",
    "    text = re.sub(r\"(\\d)(°C)\",r\"\\1 \\2\",text) # separating °C sign from numbers\r\n",
    "    text = re.sub(r\"(\\d)([hH])\",r\"\\1 \\2\",text) # separating Hh from number\r\n",
    "    text = re.sub(r\"(\\d)([mM])\",r\"\\1 \\2\",text) # separating mM from number\r\n",
    "    text = re.sub(r\"(˚C)\",\"°C\",text) # replacing °C sign properly\r\n",
    "    text = re.sub(r\"(º C)\",\"°C\",text) # replacing °C sin properly\r\n",
    "    text = re.sub(r\"[∼~]\",\"\",text)\r\n",
    "    text = re.sub(r\"[`']\",\"\",text)\r\n",
    "    text = re.sub(r\"(^\\s[0-9]+)\",\"\",text) # replacing <space>Number from begining of the sent created by replacing Ϫ with -\r\n",
    "   \r\n",
    "    return text\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float?rq=1\r\n",
    "def is_number(s):\r\n",
    "    try:\r\n",
    "        float(s) # for int, long and float\r\n",
    "    except ValueError:\r\n",
    "        try:\r\n",
    "            complex(s) # for complex\r\n",
    "        except ValueError:\r\n",
    "            return False\r\n",
    "\r\n",
    "    return True\r\n",
    "\r\n",
    "#https://stackoverflow.com/questions/17686809/how-to-find-word-next-to-a-word-in-python\r\n",
    "def nextword(target, source):\r\n",
    "    for i, w in enumerate(source):\r\n",
    "        if w == target:\r\n",
    "            if i<len(source)-1:\r\n",
    "                return source[i+1]\r\n",
    "            else: \r\n",
    "                return \"NULL-unit\"\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "source": [
    "ts = datetime.datetime.now().strftime(\"%a%d%b%Y-%I-%M-%S%p\")\r\n",
    "counter = 0\r\n",
    "ntwriter = open(\"material-kg-rdf-\"+ts+\".nt\",\"a+\",encoding=\"utf-8\")\r\n",
    "type_def = '''<http://ontology.ontotext.com/document> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://ontology.ontotext.com/document> .\r\n",
    "<http://ontology.ontotext.com/paper> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://ontology.ontotext.com/paper> .\r\n",
    "<http://ontology.ontotext.com/paper> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://ontology.ontotext.com/document> .\r\n",
    "<http://ontology.ontotext.com/doi> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://ontology.ontotext.com/doi> .\r\n",
    "<http://ontology.ontotext.com/label> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://ontology.ontotext.com/label> .\r\n",
    "<http://ontology.ontotext.com/token> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://ontology.ontotext.com/token> .\r\n",
    "<http://ontology.ontotext.com/sentence> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://ontology.ontotext.com/sentence> .\r\n",
    "<http://ontology.ontotext.com/value> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://ontology.ontotext.com/value> .\r\n",
    "'''\r\n",
    "ntwriter.write(type_def)\r\n",
    "ntwriter.write(\"\\n\")\r\n",
    "\r\n",
    "for item in result_list:\r\n",
    "    counter +=1\r\n",
    "    # strtst = result_list[0] # 345  8743 8978  68 73 35 56\r\n",
    "    strtst = item\r\n",
    "    cleaned_sent = clean_text(strtst[\"clnsent\"])\r\n",
    "    cleaned_sent_rdf = re.sub(r\"(\\s)\",\"-\",cleaned_sent)\r\n",
    "    cleaned_sent_rdf = re.sub(r\"([<>])\",\"-\",cleaned_sent_rdf)\r\n",
    "    cleaned_sent_rdf = re.sub(r\"(%)\",\"PCTG\",cleaned_sent_rdf) # Need to remove | # space [ ] ' \" , and many more also\r\n",
    "    sent_token = strtst[\"token\"]\r\n",
    "    sent_token_rdf = re.sub(r\"(\\s)\",\"-\",sent_token)\r\n",
    "    sent_label = strtst[\"label\"]\r\n",
    "    sent_label_rdf = re.sub(r\"(\\s)\",\"-\",sent_label)\r\n",
    "    paper_name = strtst[\"papername\"]\r\n",
    "    paper_name_rdf = re.sub(r\"(\\s)\",\"-\",paper_name)\r\n",
    "    paper_name_rdf = re.sub(r\"[\\[\\]\\'\\\"\\,]\",\"\",paper_name_rdf)\r\n",
    "    paper_doi = strtst[\"doi\"]\r\n",
    "    sent_id = strtst[\"id\"]\r\n",
    "\r\n",
    "    ntwriter.write(\"<http://ontology.ontotext.com/\"+paper_name_rdf+\"> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://ontology.ontotext.com/paper> .\" + \"\\n\")\r\n",
    "    ntwriter.write(\"<http://ontology.ontotext.com/\"+paper_name_rdf+\"> <http://ontology.ontotext.com#Is_A> <http://ontology.ontotext.com/paper> .\" + \"\\n\")  #need to check this entry after visualization\r\n",
    "    ntwriter.write(\"<http://ontology.ontotext.com/\"+paper_name_rdf+\"> <http://ontology.ontotext.com#Is_A> <http://ontology.ontotext.com/document> .\" + \"\\n\")\r\n",
    "    ntwriter.write(\"<http://ontology.ontotext.com/\"+paper_doi+\"> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://ontology.ontotext.com/doi> .\" + \"\\n\")\r\n",
    "    ntwriter.write(\"<http://ontology.ontotext.com/\"+paper_doi+\"> <http://ontology.ontotext.com#Is_A> <http://ontology.ontotext.com/doi> .\" + \"\\n\")\r\n",
    "    ntwriter.write(\"<http://ontology.ontotext.com/\"+paper_name_rdf+\"> <http://ontology.ontotext.com#Contains> <http://ontology.ontotext.com/\"+paper_doi+\"> .\" + \"\\n\")\r\n",
    "    ntwriter.write(\"<http://ontology.ontotext.com/\"+cleaned_sent_rdf+\"> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://ontology.ontotext.com/sentence> .\" + \"\\n\")\r\n",
    "    ntwriter.write(\"<http://ontology.ontotext.com/\"+cleaned_sent_rdf+\"> <http://ontology.ontotext.com#Is_A> <http://ontology.ontotext.com/sentence> .\" + \"\\n\")\r\n",
    "    ntwriter.write(\"<http://ontology.ontotext.com/\"+paper_name+\"> <http://ontology.ontotext.com#Contains> <http://ontology.ontotext.com/\"+cleaned_sent_rdf+\"> .\" + \"\\n\")\r\n",
    "    ntwriter.write(\"<http://ontology.ontotext.com/\"+paper_doi+\"> <http://ontology.ontotext.com#Contains> <http://ontology.ontotext.com/\"+cleaned_sent_rdf+\"> .\" + \"\\n\")\r\n",
    "    ntwriter.write(\"<http://ontology.ontotext.com/\"+sent_token_rdf+\"> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://ontology.ontotext.com/token> .\" + \"\\n\")\r\n",
    "    ntwriter.write(\"<http://ontology.ontotext.com/\"+sent_token_rdf+\"> <http://ontology.ontotext.com#Is_A> <http://ontology.ontotext.com/token> .\" + \"\\n\")\r\n",
    "    ntwriter.write(\"<http://ontology.ontotext.com/\"+cleaned_sent_rdf+\"> <http://ontology.ontotext.com#Contains> <http://ontology.ontotext.com/\"+sent_token_rdf+\"> .\" + \"\\n\")\r\n",
    "    ntwriter.write(\"<http://ontology.ontotext.com/\"+sent_label_rdf+\"> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://ontology.ontotext.com/label> .\" + \"\\n\")\r\n",
    "    ntwriter.write(\"<http://ontology.ontotext.com/\"+sent_label_rdf+\"> <http://ontology.ontotext.com#Is_A> <http://ontology.ontotext.com/label> .\" + \"\\n\")\r\n",
    "    ntwriter.write(\"<http://ontology.ontotext.com/\"+cleaned_sent_rdf+\"> <http://ontology.ontotext.com#Contains> <http://ontology.ontotext.com/\"+sent_label_rdf+\"> .\" + \"\\n\")\r\n",
    "    ntwriter.write(\"<http://ontology.ontotext.com/\"+sent_token_rdf+\"> <http://ontology.ontotext.com#Is> <http://ontology.ontotext.com/\"+sent_label_rdf+\"> .\" + \"\\n\")\r\n",
    "    ntwriter.write(\"<http://ontology.ontotext.com/\"+paper_name_rdf+\"> <http://ontology.ontotext.com#Contains> <http://ontology.ontotext.com/\"+sent_token_rdf+\"> .\" + \"\\n\")\r\n",
    "    ntwriter.write(\"<http://ontology.ontotext.com/\"+paper_name_rdf+\"> <http://ontology.ontotext.com#Contains> <http://ontology.ontotext.com/\"+sent_label_rdf+\"> .\" + \"\\n\")\r\n",
    "    ntwriter.write(\"<http://ontology.ontotext.com/\"+paper_doi+\"> <http://ontology.ontotext.com#Contains> <http://ontology.ontotext.com/\"+sent_token_rdf+\"> .\" + \"\\n\")\r\n",
    "    ntwriter.write(\"<http://ontology.ontotext.com/\"+paper_doi+\"> <http://ontology.ontotext.com#Contains> <http://ontology.ontotext.com/\"+sent_label_rdf+\"> .\" + \"\\n\")\r\n",
    "\r\n",
    "    sent_token_position = cleaned_sent.find(sent_token)\r\n",
    "    all_toks_sent = cleaned_sent.split(\" \")\r\n",
    "    # all_numbers = re.findall(r'([-+]?[0-9]*\\.?[0-9]+)',cleaned_sent) # find all the numbers in this string\r\n",
    "\r\n",
    "    all_numbers = [x for x in all_toks_sent if is_number(x)]\r\n",
    "    if (len(all_numbers))>0:\r\n",
    "            max_pos = cleaned_sent.find(all_numbers[-1])\r\n",
    "            min_pos = cleaned_sent.find(all_numbers[0])\r\n",
    "            max_pos_value = None # \"NULL\" -- for db ops #all_numbers[-1]\r\n",
    "            min_pos_value = None # \"NULL\" -- for db ops #all_numbers[0]\r\n",
    "            max_pos_value_unit = None # \"NULL\" -- for db ops \r\n",
    "            min_pos_value_unit = None # \"NULL\" -- for db ops \r\n",
    "            \r\n",
    "            for number in all_numbers:\r\n",
    "                current_pos = cleaned_sent.find(number)\r\n",
    "                if current_pos == sent_token_position or current_pos > sent_token_position:\r\n",
    "                    max_pos = current_pos\r\n",
    "                    max_pos_value = number\r\n",
    "                elif current_pos < sent_token_position:\r\n",
    "                    min_pos = current_pos\r\n",
    "                    min_pos_value = number\r\n",
    "                # elif current_pos>sent_token_position and current_pos<max_pos:\r\n",
    "                #     max_pos = current_pos\r\n",
    "                #     max_pos_value = number\r\n",
    "            # print(cleaned_sent)\r\n",
    "            # print (\"Token: \",sent_token,\"token pos: \",sent_token_position)\r\n",
    "            # print(\"left: \",sent_token,\":\",min_pos_value)\r\n",
    "            # print(\"right: \",sent_token,\":\",max_pos_value)\r\n",
    "            if max_pos_value is not None:\r\n",
    "                max_pos_value_unit = nextword(max_pos_value,all_toks_sent)\r\n",
    "                max_pos_value_unit_rdf = re.sub(r\"(%)\",\"PCTG\",max_pos_value_unit)\r\n",
    "            if min_pos_value is not None:\r\n",
    "                min_pos_value_unit = nextword(min_pos_value,all_toks_sent)\r\n",
    "                min_pos_value_unit_rdf = re.sub(r\"(%)\",\"PCTG\",min_pos_value_unit)\r\n",
    "            \r\n",
    "            if min_pos_value_unit is not None:\r\n",
    "                ntwriter.write(\"<http://ontology.ontotext.com/\"+sent_token_rdf+\"> <http://ontology.ontotext.com#HasLvalue> <http://ontology.ontotext.com/\"+min_pos_value+\"-\"+min_pos_value_unit_rdf+\"> .\" + \"\\n\")\r\n",
    "            if max_pos_value_unit is not None:\r\n",
    "                ntwriter.write(\"<http://ontology.ontotext.com/\"+sent_token_rdf+\"> <http://ontology.ontotext.com#HasRvalue> <http://ontology.ontotext.com/\"+max_pos_value+\"-\"+max_pos_value_unit_rdf+\"> .\" + \"\\n\")\r\n",
    "            print(paper_name,\" : Processed!\")\r\n",
    "            # print (\"Token: \",sent_token,\"token pos: \",sent_token_position)\r\n",
    "            # print(\"left: \",sent_token,\":\",min_pos_value,\"-->\",min_pos_value_unit)\r\n",
    "            # print(\"right: \",sent_token,\":\",max_pos_value,\"-->\",max_pos_value_unit)\r\n",
    "            # cur1 = db.cursor()\r\n",
    "            # cur1.execute(\"UPDATE `datatable1clone` SET clnsent=%s,lvalue=%s,lunit=%s,rvalue=%s,runit=%s where id=%s\", (cleaned_sent,min_pos_value,min_pos_value_unit,max_pos_value,max_pos_value_unit,sent_id))\r\n",
    "            # db.commit()\r\n",
    "    else:\r\n",
    "        ntwriter.write(\"<http://ontology.ontotext.com/\"+sent_token_rdf+\"> <http://ontology.ontotext.com#IsNull> <http://ontology.ontotext.com/NullValue> .\" + \"\\n\")\r\n",
    "        print(paper_name,\" : Processed!\")\r\n",
    "    print(\"Sentence No: \",counter)\r\n",
    "        # print(sent_token)\r\n",
    "        # print(\"no value found\")\r\n",
    "        # cur1 = db.cursor()\r\n",
    "        # cur1.execute(\"UPDATE `datatable1clone` SET clnsent=%s,lvalue=%s,lunit=%s,rvalue=%s,runit=%s where id=%s\", (cleaned_sent,\"NULL\",\"NULL\",\"NULL\",\"NULL\",sent_id))\r\n",
    "        # db.commit()\r\n",
    "    # print(all_numbers)\r\n",
    "    # for number in all_numbers:\r\n",
    "    #     pos = cleaned_sent.find(number)\r\n",
    "    #     print(number,pos)\r\n",
    "\r\n",
    "ntwriter.close()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-268-5384213ebae9>, line 30)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-268-5384213ebae9>\"\u001b[1;36m, line \u001b[1;32m30\u001b[0m\n\u001b[1;33m    paper_name_rdf = re.sub(r\"[\\[\\]'\",]\",\"\",paper_name_rdf)\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experimental cells"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "strtst = result_list[8743]\r\n",
    "\r\n",
    "print (type(strtst))\r\n",
    "for t,l in strtst.items():\r\n",
    "    cleaned_sent = \"\"\r\n",
    "    sent_token = \"\"\r\n",
    "    if t == \"clnsent\":\r\n",
    "        cleaned_sent = clean_text(l)\r\n",
    "    if t == \"token\":\r\n",
    "        sent_token = clean_text(l)\r\n",
    "    print(cleaned_sent,\"==>\",sent_token)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "strtst = result_list[345]\r\n",
    "cleaned_sent = clean_text(strtst[\"clnsent\"])\r\n",
    "sent_token = strtst[\"token\"]\r\n",
    "all_toks_sent = cleaned_sent.split(\" \")\r\n",
    "# print (all_toks_sent)\r\n",
    "all_numbers = re.findall(r'([-+]?[0-9]*\\.?[0-9]+)',cleaned_sent)\r\n",
    "print(len(all_numbers))\r\n",
    "# pattern = re.compile(r'([-+]?[0-9]*\\.?[0-9]+)')\r\n",
    "# for m in re.finditer(pattern, cleaned_sent):\r\n",
    "#     print (m.group(),\":\",m.start())\r\n",
    "\r\n",
    "for number in all_numbers:\r\n",
    "    pos = cleaned_sent.find(number)\r\n",
    "    print(number,pos)\r\n",
    "    # print(number,\"==>\",re.search(number,cleaned_sent))\r\n",
    "\r\n",
    "max_pos = cleaned_sent.find(all_numbers[-1])\r\n",
    "min_pos = cleaned_sent.find(all_numbers[0])\r\n",
    "\r\n",
    "print(cleaned_sent,\"==>\",sent_token)\r\n",
    "print(all_numbers)\r\n",
    "print(max_pos,min_pos)\r\n",
    "print(all_numbers[0])\r\n",
    "# print (type(strtst))\r\n",
    "# for t,l in strtst.items():\r\n",
    "#     cleaned_sent = \"\"\r\n",
    "#     sent_token = \"\"\r\n",
    "#     if t == \"clnsent\":\r\n",
    "#         cleaned_sent = clean_text(l)\r\n",
    "#     if t == \"token\":\r\n",
    "#         sent_token = clean_text(l)\r\n",
    "#     print(cleaned_sent,\"==>\",sent_token)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s=\"12Ϫ15Until recently temperaturedependent studies supercapacitors assembled conventional carbonaceous materials organic electrolyte limited 70°C\"\r\n",
    "\r\n",
    "pattern = re.compile(r'([0-9]+.*)([A-Z]+)')\r\n",
    "\r\n",
    "for m in re.finditer(pattern, s):\r\n",
    "    print (m.group(2), '*', m.group(1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "i = 0\r\n",
    "for item in result_list[370]:\r\n",
    "    strtst = item\r\n",
    "    cleaned_sent = clean_text(strtst[\"clnsent\"])\r\n",
    "    sent_token = strtst[\"token\"]\r\n",
    "    print(sent_token)\r\n",
    "    print(cleaned_sent)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def is_number(s):\r\n",
    "    try:\r\n",
    "        float(s) # for int, long and float\r\n",
    "    except ValueError:\r\n",
    "        try:\r\n",
    "            complex(s) # for complex\r\n",
    "        except ValueError:\r\n",
    "            return False\r\n",
    "\r\n",
    "    return True\r\n",
    "    \r\n",
    "print(is_number(\"10000s\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "strtst = result_list[8978]\r\n",
    "cleaned_sent = clean_text(strtst[\"clnsent\"])\r\n",
    "sent_token = strtst[\"token\"]\r\n",
    "print(sent_token)\r\n",
    "print(cleaned_sent)\r\n",
    "all_toks_sent = cleaned_sent.split(\" \")\r\n",
    "all_numbers = [x for x in all_toks_sent if is_number(x)]\r\n",
    "\r\n",
    "print (all_numbers)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "############### Code backup ###################\r\n",
    "# for item in\r\n",
    "strtst = result_list[8978] # 345  8743\r\n",
    "cleaned_sent = clean_text(strtst[\"clnsent\"])\r\n",
    "sent_token = strtst[\"token\"]\r\n",
    "\r\n",
    "sent_token_position = cleaned_sent.find(sent_token)\r\n",
    "all_toks_sent = cleaned_sent.split(\" \")\r\n",
    "# all_numbers = re.findall(r'([-+]?[0-9]*\\.?[0-9]+)',cleaned_sent) # find all the numbers in this string\r\n",
    "\r\n",
    "all_numbers = [x for x in all_toks_sent if is_number(x)]\r\n",
    "if (len(all_numbers))>0:\r\n",
    "        max_pos = cleaned_sent.find(all_numbers[0])\r\n",
    "        min_pos = cleaned_sent.find(all_numbers[0])\r\n",
    "        max_pos_value = 0  #all_numbers[-1]\r\n",
    "        min_pos_value = 0  #all_numbers[0]\r\n",
    "        for number in all_numbers:\r\n",
    "            current_pos = cleaned_sent.find(number)\r\n",
    "            if current_pos < sent_token_position:\r\n",
    "                min_pos = current_pos\r\n",
    "                min_pos_value = number\r\n",
    "            elif current_pos>sent_token_position and current_pos<max_pos:\r\n",
    "                max_pos = current_pos\r\n",
    "                max_pos_value = number\r\n",
    "\r\n",
    "            print(cleaned_sent)\r\n",
    "            print (\"token pos: \",sent_token_position)\r\n",
    "            print(\"left: \",sent_token,\":\",min_pos_value)\r\n",
    "            print(\"right: \",sent_token,\":\",max_pos_value)\r\n",
    "else:\r\n",
    "    print(cleaned_sent)\r\n",
    "    print(\"no value found\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "############ Code backup db-version with left right value and units in datatable1clone ##############\r\n",
    "# db.close()\r\n",
    "db1 = pymysql.connect(host='localhost',user='root',password='',database='material-db',cursorclass=pymysql.cursors.DictCursor)\r\n",
    "for item in result_list:\r\n",
    "    # strtst = result_list[0] # 345  8743 8978  68 73 35 56\r\n",
    "    strtst = item\r\n",
    "    cleaned_sent = clean_text(strtst[\"clnsent\"])\r\n",
    "    sent_token = strtst[\"token\"]\r\n",
    "    sent_label = strtst[\"label\"]\r\n",
    "    paper_name = strtst[\"papername\"]\r\n",
    "    paper_doi = strtst[\"doi\"]\r\n",
    "    sent_id = strtst[\"id\"]\r\n",
    "\r\n",
    "    sent_token_position = cleaned_sent.find(sent_token)\r\n",
    "    all_toks_sent = cleaned_sent.split(\" \")\r\n",
    "    # all_numbers = re.findall(r'([-+]?[0-9]*\\.?[0-9]+)',cleaned_sent) # find all the numbers in this string\r\n",
    "\r\n",
    "    all_numbers = [x for x in all_toks_sent if is_number(x)]\r\n",
    "    if (len(all_numbers))>0:\r\n",
    "            max_pos = cleaned_sent.find(all_numbers[-1])\r\n",
    "            min_pos = cleaned_sent.find(all_numbers[0])\r\n",
    "            max_pos_value = \"NULL\"  #all_numbers[-1]\r\n",
    "            min_pos_value = \"NULL\"  #all_numbers[0]\r\n",
    "            max_pos_value_unit = \"NULL\"\r\n",
    "            min_pos_value_unit = \"NULL\"\r\n",
    "            \r\n",
    "            for number in all_numbers:\r\n",
    "                current_pos = cleaned_sent.find(number)\r\n",
    "                if current_pos == sent_token_position or current_pos > sent_token_position:\r\n",
    "                    max_pos = current_pos\r\n",
    "                    max_pos_value = number\r\n",
    "                elif current_pos < sent_token_position:\r\n",
    "                    min_pos = current_pos\r\n",
    "                    min_pos_value = number\r\n",
    "                # elif current_pos>sent_token_position and current_pos<max_pos:\r\n",
    "                #     max_pos = current_pos\r\n",
    "                #     max_pos_value = number\r\n",
    "            # print(cleaned_sent)\r\n",
    "            # print (\"Token: \",sent_token,\"token pos: \",sent_token_position)\r\n",
    "            # print(\"left: \",sent_token,\":\",min_pos_value)\r\n",
    "            # print(\"right: \",sent_token,\":\",max_pos_value)\r\n",
    "            if max_pos_value != \"NULL\":\r\n",
    "                max_pos_value_unit = nextword(max_pos_value,all_toks_sent)\r\n",
    "            if min_pos_value != \"NULL\":\r\n",
    "                min_pos_value_unit = nextword(min_pos_value,all_toks_sent)\r\n",
    "            print(cleaned_sent)\r\n",
    "            print (\"Token: \",sent_token,\"token pos: \",sent_token_position)\r\n",
    "            print(\"left: \",sent_token,\":\",min_pos_value,\"-->\",min_pos_value_unit)\r\n",
    "            print(\"right: \",sent_token,\":\",max_pos_value,\"-->\",max_pos_value_unit)\r\n",
    "            cur2 = db1.cursor()\r\n",
    "            cur2.execute(\"UPDATE `datatable1clone` SET clnsent=%s,lvalue=%s,lunit=%s,rvalue=%s,runit=%s where id=%s\", (cleaned_sent,min_pos_value,min_pos_value_unit,max_pos_value,max_pos_value_unit,sent_id))\r\n",
    "            db1.commit()\r\n",
    "    else:\r\n",
    "        print(cleaned_sent)\r\n",
    "        print(sent_token)\r\n",
    "        print(\"no value found\")\r\n",
    "        cur2 = db1.cursor()\r\n",
    "        cur2.execute(\"UPDATE `datatable1clone` SET clnsent=%s,lvalue=%s,lunit=%s,rvalue=%s,runit=%s where id=%s\", (cleaned_sent,\"NULL\",\"NULL\",\"NULL\",\"NULL\",sent_id))\r\n",
    "        db1.commit()\r\n",
    "    # print(all_numbers)\r\n",
    "    # for number in all_numbers:\r\n",
    "    #     pos = cleaned_sent.find(number)\r\n",
    "    #     print(number,pos)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ntwriter = open(\"material-kg-rdf-\"+ts+\".nt\",\"a+\",encoding=\"utf-8\")\r\n",
    "type_def = '''<http://ontology.ontotext.com/document> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://ontology.ontotext.com/document> .\r\n",
    "<http://ontology.ontotext.com/paper> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://ontology.ontotext.com/document> .\r\n",
    "<http://ontology.ontotext.com/doi> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://ontology.ontotext.com/doi> .\r\n",
    "<http://ontology.ontotext.com/label> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://ontology.ontotext.com/label> .\r\n",
    "<http://ontology.ontotext.com/token> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://ontology.ontotext.com/token> .\r\n",
    "<http://ontology.ontotext.com/sentence> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://ontology.ontotext.com/sentence> .\r\n",
    "<http://ontology.ontotext.com/value> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://ontology.ontotext.com/value> .\r\n",
    "'''\r\n",
    "ntwriter.write(type_def)\r\n",
    "ntwriter.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}